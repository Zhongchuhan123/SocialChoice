{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from langchain.vectorstores import FAISS \n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import Ollama\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.llms import Ollama\n",
    "from tqdm import tqdm\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.graphs.neo4j_graph import Neo4jGraph\n",
    "import random\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers.fix import OutputFixingParser\n",
    "from langchain.output_parsers.retry import RetryOutputParser\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "from enum import Enum\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.output_parsers.retry import RetryOutputParser, OutputParserException\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompt_values import StringPromptValue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>item_3</th>\n",
       "      <th>item_4</th>\n",
       "      <th>item_5</th>\n",
       "      <th>item_6</th>\n",
       "      <th>item_7</th>\n",
       "      <th>item_8</th>\n",
       "      <th>item_9</th>\n",
       "      <th>...</th>\n",
       "      <th>item_42</th>\n",
       "      <th>item_43</th>\n",
       "      <th>item_44</th>\n",
       "      <th>item_45</th>\n",
       "      <th>item_46</th>\n",
       "      <th>item_47</th>\n",
       "      <th>item_48</th>\n",
       "      <th>item_49</th>\n",
       "      <th>item_50</th>\n",
       "      <th>groupId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_4856</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_58959</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_55428</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_76123</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_63417</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>user_70989</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>user_10003</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>user_15895</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>user_60908</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>user_20707</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1160 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_1  item_2  item_3  item_4  item_5  item_6  item_7  \\\n",
       "0      user_4856       3       1       2       1       5       1       2   \n",
       "1     user_58959       7       1       1       8       2       7       2   \n",
       "2     user_55428       7       5       3       9       7       7       1   \n",
       "3     user_76123       7       3       4       7      10       8       3   \n",
       "4     user_63417       1       6      10       3       7       4       1   \n",
       "...          ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "1155  user_70989       4       6       4       1       4       1       5   \n",
       "1156  user_10003       6       4       1      10       2       2      10   \n",
       "1157  user_15895       7       5       3       7       4       9       3   \n",
       "1158  user_60908       6       3       4       5       1       9       1   \n",
       "1159  user_20707       3       7       7       3       6       1       5   \n",
       "\n",
       "      item_8  item_9  ...  item_42  item_43  item_44  item_45  item_46  \\\n",
       "0          4       8  ...        6        5        4        2        5   \n",
       "1          3       7  ...        9        6        9        9        5   \n",
       "2          3       7  ...        7        3        7        4        2   \n",
       "3          3       2  ...        1        2        4        9        5   \n",
       "4          4       2  ...        2        1        4        4        9   \n",
       "...      ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "1155       8       8  ...        6        5        4        1        4   \n",
       "1156       4       9  ...        3        5        8        9        1   \n",
       "1157       3       4  ...        3        3        6        5        6   \n",
       "1158       7       6  ...        8        6        9        9        5   \n",
       "1159       8       1  ...        2        7        7       10        9   \n",
       "\n",
       "      item_47  item_48  item_49  item_50  groupId  \n",
       "0           5        2        2        4      751  \n",
       "1          10       10        7        2      751  \n",
       "2           2       10        9       10      751  \n",
       "3          10        4        3        3      751  \n",
       "4           4        8        7        6      752  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "1155        5       10       10        4      999  \n",
       "1156        6        3        8        7      999  \n",
       "1157        5        9       10       10      999  \n",
       "1158        2        5        9        1     1000  \n",
       "1159       10        3        7        4     1000  \n",
       "\n",
       "[1160 rows x 52 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################\n",
    "total = 250\n",
    "num_members = [2,4,8]\n",
    "\n",
    "\n",
    "num_items = 50  #### [5,10,25,50,100]\n",
    "##################\n",
    "## Datasets are named after num_members, num_items and total groups\n",
    "\n",
    "\n",
    "file = f'groups/groups_{num_members}members_{num_items}items_totalgroups{total}.csv'\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions:\n",
    "\n",
    "def transform_df(df):\n",
    "    df_long = df.melt(id_vars=['groupId', 'user_id'], var_name='item', value_name='rating')\n",
    "    return df_long\n",
    "\n",
    "def listmaker(value):\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            value = [value]\n",
    "        except (ValueError, SyntaxError):\n",
    "            print(f\"ERROR MAKING A LIST?!\")\n",
    "            return []  \n",
    "    return value if isinstance(value, list) else []  \n",
    "\n",
    "\n",
    "## Social choice-based aggregation strategies:\n",
    "\n",
    "def MAJ(df):\n",
    "    counts = df.groupby(['groupId', 'item']).size().reset_index(name='count')\n",
    "    return list(counts.loc[counts['count'].values ==counts['count'].values.max()].item)\n",
    "\n",
    "def ADD(df):\n",
    "    counts = df.groupby(['groupId', 'item'])['rating'].sum().reset_index(name='sum_rating')\n",
    "    return list(counts.loc[counts['sum_rating'].values ==counts['sum_rating'].values.max()].item)\n",
    "    \n",
    "def APP(df, threshold=6):\n",
    "    above_threshold = df[df['rating'] > threshold]\n",
    "    counts = above_threshold.groupby(['groupId', 'item']).size().reset_index(name='count_above_threshold')\n",
    "    return list(counts.loc[counts['count_above_threshold'].values ==counts['count_above_threshold'].values.max()].item)\n",
    "\n",
    "def LMS(df):\n",
    "    counts = df.groupby(['groupId', 'item'])['rating'].min().reset_index(name='min_rating')\n",
    "    return list(counts.loc[counts['min_rating'].values ==counts['min_rating'].values.max()].item)\n",
    "\n",
    "def MPL(df):\n",
    "    counts = df.groupby(['groupId', 'item'])['rating'].max().reset_index(name='max_rating')\n",
    "    \n",
    "    return list(counts.loc[counts['max_rating'].values ==counts['max_rating'].values.max()].item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Descriptions taken from earlier work by Francesco + 2 item example\n",
    "\n",
    "strat_list = [\n",
    "'ADD: ADD sums all ratings per item and recommend the item with the highest sum (Senot et al. 2010). For example, the first item has a 4 rating and 5 rating (sum=9). The second item has a 6 and 7 rating (sum=13). Recommend the second item because its sum is higher than the sum of the first item. Use ADD to refer to this strategy.',\n",
    "'APP: APP is a majority-based strategy. A predefined threshold is set at 6. For each item, you count the number of times it has been rated above 6. Recommend the item which has been rated above the threshold the most. For example, the first item has a rating of 7 and 8. The second item has a rating of 9 and 5. Recommend the first item because it has more ratings above 6. Use APP to refer to this strategy.',\n",
    "'LMS: LMS recommends the item which has the highest rating if you only take the lowest rating per item into account (Senot et al. 2010). For example, the first item has a rating of 5 and 6. The second item has a rating of 2 and 9. Recommend the first item because its lowest rating (5) is higher than the lowest rating of the second item (2). Use LMS to refer to this strategy.',\n",
    "'MPL: MPL recommends the item with the highest single rating across all relevant individuals (Senot et al. 2010). For example, the first item has a rating of 5 and 6. The second item has a rating of 2 and 9. Recommend the second item because 9 is the highest rating across all items. Use MPL to refer to this strategy.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FULL INITIALIZATION OF ALL LLM CHAINS\n",
    "## A llm chain consists of three parts 1) prompt 2) model 3) parser\n",
    "\n",
    "\n",
    "#### 1) Prompt + parser\n",
    "class Recommendation(BaseModel):\n",
    "    strategy: str = Field(description=\"The aggregation strategy that was used\")\n",
    "    recommendation: str = Field(description=\"python list of the final group recommendation\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Recommendation)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Only respond with the required json format. \n",
    "    The only response is a json dictionary with the strategy and recommendation keys. Follow these formatting instructions:\n",
    "    \\n\n",
    "    {format_instructions}\\n \n",
    "\n",
    "    #######\n",
    "    \n",
    "    You are an expert in making group recommendations based on a table of ratings presented below. \n",
    "    That information includes users (user_ids) and information on which items they like (item_x). The rating is a scale from 0 to 10. \n",
    "    You recommend an item to the group. For the recommendation, you simply mention the item name. \n",
    "\n",
    "    The table is found below:\n",
    "    \n",
    "    ## begin group table ##\n",
    "    {desc}\n",
    "    ## end group table ##\n",
    "    \n",
    "    To obtain a group recommendation, you follow a social choice-based aggregation strategy. The strategy is explained (alongside a simple example) in the following excerpt:\n",
    "    \n",
    "    ## begin strategy excerpt ##\n",
    "    {strat}\n",
    "    ## end strategy excerpt ##\n",
    "   \n",
    "    Based on the described group composition, you strictly apply the procedure of the aggregation strategy on the group table to obtain a group recommendation. Do not write python code.\n",
    "    \n",
    "    If multiple items have the same end score, recommend them both in the form of a list. If there is a tie, recommend the set of items in the tie. Refer to items using their name (item_value)\n",
    "    \n",
    "\n",
    "    \n",
    "     If you do not know the answer, respond with an empty list in the recommendation key. Follow the instructions:\n",
    "    ## begin instructions ##\n",
    "    \\n\n",
    "    {format_instructions}\\n \n",
    "    ## end instructions ##\n",
    "\n",
    "    Only respond with the requested JSON dictionary which includes the recommendation and strategy keys.\n",
    "    \"\"\" ,\n",
    "    input_variables=[\"desc\", \"strat\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 2) MODELS\n",
    "llm_llama = ChatOllama(model='llama3.1:8b-instruct-q8_0', temperature=0, max_tokens=1000,seed=1234) \n",
    "llm_mistral = ChatOllama(model='mistral:instruct', temperature=0, max_tokens=1000,seed=1234) \n",
    "llm_gemma = ChatOllama(model='gemma2', temperature=0, max_tokens=1000,seed=1234) \n",
    "llm_phi = ChatOllama(model='phi4', temperature=0, max_tokens=1000,seed=1234) \n",
    "\n",
    "\n",
    "\n",
    "## full chains\n",
    "\n",
    "chain_llama = prompt | llm_llama | parser\n",
    "chain_mistral = prompt | llm_mistral | parser\n",
    "chain_gemma = prompt | llm_gemma | parser\n",
    "chain_phi = prompt | llm_phi| parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123456) \n",
    "np.random.seed(123456)\n",
    "\n",
    "\n",
    "result_file = f'YOUR FILE NAME'\n",
    "result_exists = os.path.isfile(result_file)\n",
    "\n",
    "###############################\n",
    "\n",
    "if result_exists == True:\n",
    "    done = pd.read_csv(result_file)\n",
    "    counter = done['groupId'].max() +1\n",
    "    max_counter = df['groupId'].max()\n",
    "\n",
    "else:\n",
    "    counter = df['groupId'].min()\n",
    "    max_counter = df['groupId'].max()\n",
    "    #max_counter = df['groupId'].min() + 3\n",
    "###############################\n",
    "\n",
    "print(counter)\n",
    "\n",
    "strategy_map = {\n",
    "    'ADD': ADD,\n",
    "    'APP': APP,\n",
    "    'LMS': LMS,\n",
    "    'MPL': MPL\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "while counter <= max_counter:\n",
    "    df_members = df.loc[df['groupId'] == counter]\n",
    "\n",
    "    chosen_strat = random.choice(strat_list)\n",
    "    try:\n",
    "        \n",
    "        responses = {\n",
    "            \"llama\": chain_llama.invoke({\"desc\": df_members.iloc[:, :-1].to_dict(orient='list'),'strat':chosen_strat}),\n",
    "            \"mistral\": chain_mistral.invoke({\"desc\": df_members.iloc[:, :-1].to_dict(orient='list'),'strat':chosen_strat}),\n",
    "            \"gemma\": chain_gemma.invoke({\"desc\": df_members.iloc[:, :-1].to_dict(orient='list'),'strat':chosen_strat}),\n",
    "            \"deepseek\": chain_deepseek.invoke({\"desc\": df_members,'strat':chosen_strat}),\n",
    "            \"phi\": chain_phi.invoke({\"desc\": df_members.iloc[:, :-1].to_dict(orient='list'),'strat':chosen_strat}),\n",
    "        }\n",
    "\n",
    "        if responses['phi']['strategy'] in strategy_map:\n",
    "            final_strat = responses['phi']['strategy']\n",
    "            gold_label = strategy_map.get(responses['phi']['strategy'])(transform_df(df_members))\n",
    "        elif responses['mistral']['strategy'] in strategy_map:\n",
    "            final_strat = responses['mistral']['strategy']\n",
    "            gold_label = strategy_map.get(responses['mistral']['strategy'])(transform_df(df_members)) ### sometimes a formatting error can occur.\n",
    "        else:\n",
    "            counter+=1\n",
    "            print('fail', counter)\n",
    "            continue\n",
    "\n",
    "        recs = {key: listmaker(res[\"recommendation\"]) for key, res in responses.items()}\n",
    "\n",
    "        df_temp = pd.DataFrame([{\n",
    "                \"groupId\": counter,\n",
    "                \"group_size\":len(df_members),\n",
    "                \"num_items\": int(len(list(df_members))-2), ## num columns - user_id column - groupid column\n",
    "                \"strategy\": final_strat,\n",
    "                \"gold_label\": gold_label,\n",
    "                **{f\"{key}\": vec for key, vec in recs.items()} \n",
    "            }])\n",
    "\n",
    "        df_temp.to_csv(result_file, mode='a', index=False, header=not result_exists)\n",
    "        result_exists = True\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing group {counter}: {e}\")\n",
    "    counter +=1\n",
    "\n",
    "\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPLANATIONS ( LOOP ABOVE WAS USED TO RUN CODE) #########\n",
    "### Few shot uses own loop ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "##### PROMPT WITH EXPLANATIONS\n",
    "#############\n",
    "\n",
    "\n",
    "#### 1) Prompt + parser\n",
    "class Recommendation(BaseModel):\n",
    "    strategy: str = Field(description=\"The aggregation strategy that was used\")\n",
    "    recommendation: str = Field(description=\"python list of the final group recommendation\")\n",
    "    explanation: str = Field(description=\"a short explanation detailing the recommendation procedure\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Recommendation)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Only respond with the required json format. \n",
    "    The only response is a json dictionary with the strategy, recommendation and explanation keys. Follow these formatting instructions:\n",
    "    \\n\n",
    "    {format_instructions}\\n \n",
    "\n",
    "    #######\n",
    "    \n",
    "    You are an expert in making and explaining group recommendations based on a table of ratings presented below. \n",
    "    That information includes users (user_ids) and information on which items they like (item_x). The rating is a scale from 0 to 10. \n",
    " You recommend an item to the group. For the recommendation, you simply mention the item name. \n",
    "\n",
    "    The table is found below:\n",
    "    \n",
    "    ## begin group table ##\n",
    "    {desc}\n",
    "    ## end group table ##\n",
    "    \n",
    "    To obtain a group recommendation, you follow a social choice-based aggregation strategy. The strategy is explained (alongside a simple example) in the following excerpt:\n",
    "    \n",
    "    ## begin strategy excerpt ##\n",
    "    {strat}\n",
    "    ## end strategy excerpt ##\n",
    "  \n",
    "\n",
    "    Based on the described group composition, you strictly apply the procedure of the aggregation strategy on the group table to obtain a group recommendation. Do not write python code.\n",
    "    \n",
    "    If multiple items have the same end score, recommend them both in the form of a list. If there is a tie, recommend the set of items in the tie. Refer to items using their name (item_value)\n",
    "    Provide a short explanation detailing how you derived the recommendation. Explain to the group how the strategy works and why the output is being recommended to them.\n",
    "    \n",
    "    \n",
    "\n",
    "   Only respond with the requested JSON dictionary which includes the recommendation, strategy and explanaiton keys.\n",
    "    ## begin instructions ##\n",
    "    \\n\n",
    "    {format_instructions}\\n \n",
    "    ## end instructions ##\n",
    "    \"\"\" ,\n",
    "    input_variables=[\"desc\", \"strat\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 2) MODELS\n",
    "llm_llama = ChatOllama(model='llama3.1:8b-instruct-q8_0', temperature=0, max_tokens=1000,seed=1234) \n",
    "llm_mistral = ChatOllama(model='mistral:instruct', temperature=0, max_tokens=1000,seed=1234) \n",
    "llm_gemma = ChatOllama(model='gemma2', temperature=0, max_tokens=1000,seed=1234) \n",
    "llm_phi = ChatOllama(model='phi4', temperature=0, max_tokens=1000,seed=1234) \n",
    "\n",
    "\n",
    "\n",
    "## full chains\n",
    "\n",
    "chain_llama = prompt | llm_llama | parser\n",
    "chain_mistral = prompt | llm_mistral | parser\n",
    "chain_gemma = prompt | llm_gemma | parser\n",
    "chain_phi = prompt | llm_phi| parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'strategy': 'ADD',\n",
       " 'recommendation': ['item_7'],\n",
       " 'explanation': \"The ADD strategy sums all ratings per item and recommends the item with the highest sum. In this case, 'item_7' has the highest total score of 30 across all users in the group, making it the top recommendation.\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_phi.invoke({\"desc\": df[df.groupId==501], 'strat': strat_list[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FEW SHOT #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1501, 1502, 1503]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs= pd.read_csv('group_data/fewshot-examples.csv')\n",
    "fs_list = list(set(fs.groupId))\n",
    "fs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FULL INITIALIZATION OF ALL LLM CHAINS\n",
    "## A llm chain consists of three parts 1) prompt 2) model 3) parser\n",
    "\n",
    "\n",
    "#### 1) Prompt + parser\n",
    "class Recommendation(BaseModel):\n",
    "    strategy: str = Field(description=\"The aggregation strategy that was used\")\n",
    "    recommendation: str = Field(description=\"python list of the final group recommendation\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Recommendation)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Only respond with the required json format. \n",
    "    The only response is a json dictionary with the strategy and recommendation keys. Follow these formatting instructions:\n",
    "    \\n\n",
    "    {format_instructions}\\n \n",
    "\n",
    "    #######\n",
    "    \n",
    "    You are an expert in making group recommendations based on a table of ratings presented below. \n",
    "    That information includes users (user_ids) and information on which items they like (item_x). The rating is a scale from 0 to 10. \n",
    "    You recommend an item to the group. For the recommendation, you simply mention the item name. \n",
    "\n",
    "    To obtain a group recommendation, you follow a social choice-based aggregation strategy. \n",
    "   \n",
    "    \n",
    "     \n",
    "    To showcase how to apply the strategy, you are provided with these examples.\n",
    "    If the input would be {example1in}, the recommendation would be {example1out}.\n",
    "    If the input would be {example2in}, the recommendation would be {example2out}.\n",
    "    If the input would be {example3in}, the recommendation would be {example3out}.\n",
    "\n",
    "    The strategy is explained (alongside another simple example) in the following excerpt:\n",
    "    \n",
    "    ## begin strategy excerpt ##\n",
    "    {strat}\n",
    "    ## end strategy excerpt ##\n",
    "    Based on the described group composition, you strictly apply the procedure of the aggregation strategy on the group table to obtain a group recommendation. Do not write python code.\n",
    "    If multiple items have the same end score, recommend them both in the form of a list. If there is a tie, recommend the set of items in the tie. Refer to items using their name (item_value)\n",
    "    Apply the strategy described in the strategy excerpt and showcases in the three examples on the following group table.\n",
    "    \n",
    "    ## begin group table ##\n",
    "    {desc}\n",
    "    ## end group table ##\n",
    "    \n",
    "\n",
    "    Do not write python code. Only respond with the requested JSON dictionary which includes the recommendation (items) and strategy keys.\n",
    "    ## begin instructions ##\n",
    "    \\n\n",
    "    {format_instructions}\\n \n",
    "    ## end instructions ##\n",
    "    \"\"\" ,\n",
    "    input_variables=[\"desc\", \"strat\", 'example1in', 'example1out', 'example2in', 'example2out', 'example3in', 'example3out'],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm_phi = ChatOllama(model='phi4', temperature=0, max_tokens=1000,seed=1234) \n",
    "\n",
    "## full chains\n",
    "chain_phi = prompt | llm_phi| parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'strategy': 'Average Score Strategy',\n",
       " 'recommendation': ['item_37', 'item_42', 'item_47', 'item_46', 'item_40']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_index = random.choice([2])\n",
    "chosen_strat = strat_list[random_index]\n",
    "strat_func = [ADD, APP, LMS, MPL]\n",
    "\n",
    "\n",
    "selected_func = strat_func[random_index]\n",
    "\n",
    "chain_phi.invoke({\n",
    "    \"desc\": df[df.groupId == 850].iloc[:, :-1].to_dict(orient='list'),\n",
    "    \"strat\": chosen_strat,\n",
    "    \"example1in\": fs[fs.groupId == fs_list[0]].iloc[:, :-1].to_dict(orient='list'),\n",
    "    \"example1out\": selected_func(transform_df(fs[fs.groupId == fs_list[0]])),\n",
    "    \"example2in\": fs[fs.groupId == fs_list[1]].iloc[:, :-1].to_dict(orient='list'),\n",
    "    \"example2out\": selected_func(transform_df(fs[fs.groupId == fs_list[1]])),\n",
    "    \"example3in\": fs[fs.groupId == fs_list[2]].iloc[:, :-1].to_dict(orient='list'),\n",
    "    \"example3out\": selected_func(transform_df(fs[fs.groupId == fs_list[2]]))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_14', 'item_33', 'item_38', 'item_42']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LMS(transform_df(df[df.groupId==850]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123456) \n",
    "np.random.seed(123456)\n",
    "\n",
    "\n",
    "result_file = f'results/all_results-fs-mistral.csv'\n",
    "result_exists = os.path.isfile(result_file)\n",
    "\n",
    "###############################\n",
    "\n",
    "if result_exists == True:\n",
    "    done = pd.read_csv(result_file)\n",
    "    counter = done['groupId'].max() +1\n",
    "    max_counter = df['groupId'].max()\n",
    "\n",
    "else:\n",
    "    counter = df['groupId'].min()\n",
    "    max_counter = df['groupId'].max()\n",
    "    #max_counter = df['groupId'].min() + 3\n",
    "###############################\n",
    "\n",
    "print(counter)\n",
    "\n",
    "strategy_map = {\n",
    "    'ADD': ADD,\n",
    "    'APP': APP,\n",
    "    'LMS': LMS,\n",
    "    'MPL': MPL\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "while counter <= max_counter:\n",
    "    df_members = df.loc[df['groupId'] == counter]\n",
    "\n",
    "    random_index = random.choice([0,1,2,3])\n",
    "    chosen_strat = strat_list[random_index]\n",
    "    strat_func = [ADD, APP, LMS, MPL]\n",
    "    strat_str = ['ADD', 'APP', 'LMS', 'MPL']\n",
    "    selected_func = strat_func[random_index]\n",
    "\n",
    "\n",
    "    try:\n",
    "        \n",
    "        responses = {'phi':chain_phi.invoke({\n",
    "                        \"desc\":df_members.iloc[:, :-1].to_dict(orient='list'),\n",
    "                        \"strat\": chosen_strat,\n",
    "                        \"example1in\": fs[fs.groupId == fs_list[0]].iloc[:, :-1].to_dict(orient='list'),\n",
    "                        \"example1out\": selected_func(transform_df(fs[fs.groupId == fs_list[0]])),\n",
    "                        \"example2in\": fs[fs.groupId == fs_list[1]].iloc[:, :-1].to_dict(orient='list'),\n",
    "                        \"example2out\": selected_func(transform_df(fs[fs.groupId == fs_list[1]])),\n",
    "                        \"example3in\": fs[fs.groupId == fs_list[2]].iloc[:, :-1].to_dict(orient='list'),\n",
    "                        \"example3out\": selected_func(transform_df(fs[fs.groupId == fs_list[2]]))\n",
    "        })\n",
    "        }\n",
    "\n",
    "       \n",
    "        final_strat = strat_str[random_index]\n",
    "        gold_label = selected_func(transform_df(df_members))\n",
    "        #else:\n",
    "            #final_strat = responses['phi']['strategy']\n",
    "            #gold_label = strategy_map.get(responses['phi']['strategy'])(transform_df(df_members)) ### sometimes a formatting error can occur.\n",
    "      \n",
    "\n",
    "        recs = {key: listmaker(res[\"recommendation\"]) for key, res in responses.items()}\n",
    "\n",
    "        df_temp = pd.DataFrame([{\n",
    "                \"groupId\": counter,\n",
    "                \"group_size\":len(df_members),\n",
    "                \"num_items\": int(len(list(df_members))-2), ## num columns - user_id column - groupid column\n",
    "                \"strategy\": final_strat,\n",
    "                \"gold_label\": gold_label,\n",
    "                **{f\"{key}\": vec for key, vec in recs.items()} \n",
    "            }])\n",
    "\n",
    "        df_temp.to_csv(result_file, mode='a', index=False, header=not result_exists)\n",
    "        result_exists = True\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing group {counter}: {e}\")\n",
    "    counter +=1\n",
    "\n",
    "\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_members = df.loc[df['groupId'] == 751]\n",
    "\n",
    "random_index = random.choice([0,1,2,3])\n",
    "chosen_strat = strat_list[random_index]\n",
    "strat_func = [ADD, APP, LMS, MPL]\n",
    "strat_str = ['ADD', 'APP', 'LMS', 'MPL']\n",
    "selected_func = strat_func[random_index]\n",
    "\n",
    "\n",
    "responses = {\n",
    "            'phi':chain_phi.invoke({\n",
    "                        \"desc\":df_members.iloc[:, :-1].to_dict(orient='list'),\n",
    "                        \"strat\": chosen_strat,\n",
    "                        \"example1in\": fs[fs.groupId == fs_list[0]].iloc[:, :-1].to_dict(orient='list'),\n",
    "                        \"example1out\": selected_func(transform_df(fs[fs.groupId == fs_list[0]])),\n",
    "                        \"example2in\": fs[fs.groupId == fs_list[1]].iloc[:, :-1].to_dict(orient='list'),\n",
    "                        \"example2out\": selected_func(transform_df(fs[fs.groupId == fs_list[1]])),\n",
    "                        \"example3in\": fs[fs.groupId == fs_list[2]].iloc[:, :-1].to_dict(orient='list'),\n",
    "                        \"example3out\": selected_func(transform_df(fs[fs.groupId == fs_list[2]]))\n",
    "        })\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### BASELINE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FULL INITIALIZATION OF ALL LLM CHAINS\n",
    "## A llm chain consists of three parts 1) prompt 2) model 3) parser\n",
    "\n",
    "\n",
    "#### 1) Prompt + parser\n",
    "class Recommendation(BaseModel):\n",
    "    strategy: str = Field(description=\"The aggregation strategy that was used\")\n",
    "    recommendation: str = Field(description=\"python list of the final group recommendation\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Recommendation)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Only respond with the required json format. \n",
    "    The only response is a json dictionary with the strategy and recommendation keys. Follow these formatting instructions:\n",
    "    \\n\n",
    "    {format_instructions}\\n \n",
    "\n",
    "    #######\n",
    "    \n",
    "    You are an expert in making group recommendations based on a table of ratings presented below. \n",
    "    That information includes users (user_ids) and information on which items they like (item_x). The rating is a scale from 0 to 10. \n",
    "    You recommend an item to the group. For the recommendation, you simply mention the item name. \n",
    "\n",
    "    The table is found below:\n",
    "    \n",
    "    ## begin group table ##\n",
    "    {desc}\n",
    "    ## end group table ##\n",
    "    \n",
    "    To obtain a group recommendation, you follow a social choice-based aggregation strategy. The strategy is explained (alongside a simple example) in the following excerpt:\n",
    "    \n",
    "    ## begin strategy excerpt ##\n",
    "    {strat}\n",
    "    ## end strategy excerpt ##\n",
    "   \n",
    "    Based on the described group composition, you strictly apply the procedure of the aggregation strategy on the group table to obtain a group recommendation. Do not write python code.\n",
    "    \n",
    "    If multiple items have the same end score, recommend them both in the form of a list. If there is a tie, recommend the set of items in the tie. Refer to items using their name (item_value)\n",
    "    \n",
    "\n",
    "    \n",
    "     If you do not know the answer, respond with an empty list in the recommendation key. \n",
    "         \n",
    "    Follow the instructions:\n",
    "    ## begin instructions ##\n",
    "    \\n\n",
    "    {format_instructions}\\n \n",
    "    ## end instructions ##\n",
    "    Only respond with the requested JSON dictionary which includes the recommendation and strategy keys.\n",
    "    \"\"\" ,\n",
    "    input_variables=[\"desc\", \"strat\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "llm_phi = ChatOllama(model='phi4', temperature=0, max_tokens=1000,seed=1234) \n",
    "chain_phi = prompt | llm_phi| parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### BASELINE RUN FOR ONLY PART 2 ####\n",
    "random.seed(123456) \n",
    "np.random.seed(123456)\n",
    "\n",
    "\n",
    "result_file = f'results/all_results-baseline.csv'\n",
    "result_exists = os.path.isfile(result_file)\n",
    "\n",
    "###############################\n",
    "\n",
    "if result_exists == True:\n",
    "    done = pd.read_csv(result_file)\n",
    "    counter = done['groupId'].max() +1\n",
    "    max_counter = df['groupId'].max()\n",
    "\n",
    "else:\n",
    "    counter = df['groupId'].min()\n",
    "    max_counter = df['groupId'].max()\n",
    "    #max_counter = df['groupId'].min() + 3\n",
    "###############################\n",
    "\n",
    "print(counter)\n",
    "\n",
    "strategy_map = {\n",
    "    'ADD': ADD,\n",
    "    'APP': APP,\n",
    "    'LMS': LMS,\n",
    "    'MPL': MPL\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "while counter <= max_counter:\n",
    "    df_members = df.loc[df['groupId'] == counter]\n",
    "\n",
    "    random_index = random.choice([0,1,2,3])\n",
    "    chosen_strat = strat_list[random_index]\n",
    "    strat_func = [ADD, APP, LMS, MPL]\n",
    "    strat_str = ['ADD', 'APP', 'LMS', 'MPL']\n",
    "    selected_func = strat_func[random_index]\n",
    "    try:\n",
    "        \n",
    "        responses = {\n",
    "\n",
    "            \"phi\": chain_phi.invoke({\"desc\": df_members.iloc[:, :-1].to_dict(orient='list'),'strat':chosen_strat}),\n",
    "        }\n",
    "        final_strat = strat_str[random_index]\n",
    "        gold_label = selected_func(transform_df(df_members))\n",
    "\n",
    "        recs = {key: listmaker(res[\"recommendation\"]) for key, res in responses.items()}\n",
    "\n",
    "        df_temp = pd.DataFrame([{\n",
    "                \"groupId\": counter,\n",
    "                \"group_size\":len(df_members),\n",
    "                \"num_items\": int(len(list(df_members))-2), ## num columns - user_id column - groupid column\n",
    "                \"strategy\": final_strat,\n",
    "                \"gold_label\": gold_label,\n",
    "                **{f\"{key}\": vec for key, vec in recs.items()} \n",
    "            }])\n",
    "\n",
    "        df_temp.to_csv(result_file, mode='a', index=False, header=not result_exists)\n",
    "        result_exists = True\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing group {counter}: {e}\")\n",
    "    counter +=1\n",
    "\n",
    "\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### WITH CONTEXT #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### CONTEXT ###########\n",
    "movies = pd.read_csv('group_data/movies.csv')\n",
    "movies = list(movies.title)\n",
    "titles = random.sample(movies,50)\n",
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FULL INITIALIZATION OF ALL LLM CHAINS\n",
    "## A llm chain consists of three parts 1) prompt 2) model 3) parser\n",
    "\n",
    "\n",
    "#### 1) Prompt + parser\n",
    "class Recommendation(BaseModel):\n",
    "    strategy: str = Field(description=\"The aggregation strategy that was used\")\n",
    "    recommendation: str = Field(description=\"python list of the final group recommendation\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Recommendation)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Only respond with the required json format. \n",
    "    The only response is a json dictionary with the strategy and recommendation keys. Follow these formatting instructions:\n",
    "    \\n\n",
    "    {format_instructions}\\n \n",
    "\n",
    "    #######\n",
    "    \n",
    "    You are an expert in making group recommendations based on a table of ratings presented below. \n",
    "    That information includes users (user_ids) and information on which movies they like (strings with movie titles). The rating is a scale from 0 to 10. \n",
    "    You recommend a movie to the group. For the recommendation, you simply mention the movie title. \n",
    "\n",
    "    The table is found below:\n",
    "    \n",
    "    ## begin group table ##\n",
    "    {desc}\n",
    "    ## end group table ##\n",
    "    \n",
    "    To obtain a group recommendation, you follow a social choice-based aggregation strategy. The strategy is explained (alongside a simple example) in the following excerpt:\n",
    "    \n",
    "    ## begin strategy excerpt ##\n",
    "    {strat}\n",
    "    ## end strategy excerpt ##\n",
    "   \n",
    "    Based on the described group composition, you strictly apply the procedure of the aggregation strategy on the group table to obtain a group recommendation. Do not write python code.\n",
    "    \n",
    "    If multiple movies have the same end score, recommend them both in the form of a list. If there is a tie, recommend the set of movies in the tie. Refer to movies using their full title.\n",
    "    \n",
    "\n",
    "    \n",
    "     If you do not know the answer, respond with an empty list in the recommendation key. \n",
    "         \n",
    "    Follow the instructions:\n",
    "    ## begin instructions ##\n",
    "    \\n\n",
    "    {format_instructions}\\n \n",
    "    ## end instructions ##\n",
    "    Only respond with the requested JSON dictionary which includes the recommendation and strategy keys.\n",
    "    \"\"\" ,\n",
    "    input_variables=[\"desc\", \"strat\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "llm_phi = ChatOllama(model='phi4', temperature=0, max_tokens=1000,seed=1234) \n",
    "chain_phi = prompt | llm_phi| parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['user_id']\n",
    "cols.extend(random.sample(titles, int(len(list(df_members))-2)))\n",
    "cols.extend(['groupId'])\n",
    "df_members.columns = cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### BASELINE RUN FOR ONLY PART 2 ####\n",
    "random.seed(123456) \n",
    "np.random.seed(123456)\n",
    "\n",
    "\n",
    "result_file = f'results/all_results-context.csv'\n",
    "result_exists = os.path.isfile(result_file)\n",
    "\n",
    "###############################\n",
    "\n",
    "if result_exists == True:\n",
    "    done = pd.read_csv(result_file)\n",
    "    counter = done['groupId'].max() +1\n",
    "    max_counter = df['groupId'].max()\n",
    "\n",
    "else:\n",
    "    counter = df['groupId'].min()\n",
    "    max_counter = df['groupId'].max()\n",
    "    #max_counter = df['groupId'].min() + 3\n",
    "###############################\n",
    "\n",
    "print(counter)\n",
    "\n",
    "strategy_map = {\n",
    "    'ADD': ADD,\n",
    "    'APP': APP,\n",
    "    'LMS': LMS,\n",
    "    'MPL': MPL\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "while counter <= max_counter:\n",
    "    df_members = df.loc[df['groupId'] == counter]\n",
    "    \n",
    "    # setting movie titles as columns instead of item_x\n",
    "    cols = ['user_id']\n",
    "    cols.extend(random.sample(titles, int(len(list(df_members))-2)))\n",
    "    cols.extend(['groupId'])\n",
    "    df_members.columns = cols\n",
    "\n",
    "\n",
    "    random_index = random.choice([0,1,2,3])\n",
    "    chosen_strat = strat_list[random_index]\n",
    "    strat_func = [ADD, APP, LMS, MPL]\n",
    "    strat_str = ['ADD', 'APP', 'LMS', 'MPL']\n",
    "    selected_func = strat_func[random_index]\n",
    "    try:\n",
    "        \n",
    "        responses = {\n",
    "            \"phi\": chain_phi.invoke({\"desc\": df_members.iloc[:, :-1].to_dict(orient='list'),'strat':chosen_strat}),\n",
    "        }\n",
    "        final_strat = strat_str[random_index]\n",
    "        gold_label = selected_func(transform_df(df_members))\n",
    "\n",
    "        recs = {key: listmaker(res[\"recommendation\"]) for key, res in responses.items()}\n",
    "\n",
    "        df_temp = pd.DataFrame([{\n",
    "                \"groupId\": counter,\n",
    "                \"group_size\":len(df_members),\n",
    "                \"num_items\": int(len(list(df_members))-2), ## num columns - user_id column - groupid column\n",
    "                \"strategy\": final_strat,\n",
    "                \"gold_label\": gold_label,\n",
    "                **{f\"{key}\": vec for key, vec in recs.items()} \n",
    "            }])\n",
    "\n",
    "        df_temp.to_csv(result_file, mode='a', index=False, header=not result_exists)\n",
    "        result_exists = True\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing group {counter}: {e}\")\n",
    "    counter +=1\n",
    "\n",
    "\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEST CASE: DATA FORMATTING\n",
    "\n",
    "#### FULL INITIALIZATION OF ALL LLM CHAINS\n",
    "## A llm chain consists of three parts 1) prompt 2) model 3) parser\n",
    "\n",
    "\n",
    "#### 1) Prompt + parser\n",
    "class Recommendation(BaseModel):\n",
    "    strategy: str = Field(description=\"The aggregation strategy that was used\")\n",
    "    recommendation: str = Field(description=\"python list of the final group recommendation\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Recommendation)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Only respond with the required json format. \n",
    "    The only response is a json dictionary with the strategy and recommendation keys. Follow these formatting instructions:\n",
    "    \\n\n",
    "    {format_instructions}\\n \n",
    "\n",
    "    #######\n",
    "    \n",
    "    You are an expert in making group recommendations based on a table of ratings presented below. \n",
    "    That information includes users (user_ids) and information on which items they like (item_x). The rating is a scale from 0 to 10. \n",
    "    You recommend an item to the group. For the recommendation, you simply mention the item name. \n",
    "\n",
    "    The table is found below:\n",
    "    \n",
    "    ## begin group table ##\n",
    "    {desc}\n",
    "    ## end group table ##\n",
    "    \n",
    "    To obtain a group recommendation, you follow a social choice-based aggregation strategy. The strategy is explained (alongside a simple example) in the following excerpt:\n",
    "    \n",
    "    ## begin strategy excerpt ##\n",
    "    {strat}\n",
    "    ## end strategy excerpt ##\n",
    "   \n",
    "    Based on the described group composition, you strictly apply the procedure of the aggregation strategy on the group table to obtain a group recommendation. Do not write python code.\n",
    "    \n",
    "    If multiple items have the same end score, recommend them both in the form of a list. If there is a tie, recommend the set of items in the tie. Refer to items using their name (item_value)\n",
    "    \n",
    "\n",
    "    \n",
    "     If you do not know the answer, respond with an empty list in the recommendation key. Follow the instructions:\n",
    "    ## begin instructions ##\n",
    "    \\n\n",
    "    {format_instructions}\\n \n",
    "    ## end instructions ##\n",
    "\n",
    "    Only respond with the requested JSON dictionary which includes the recommendation and strategy keys.\n",
    "    \"\"\" ,\n",
    "    input_variables=[\"desc\", \"strat\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 2) MODELS\n",
    "\n",
    "llm_phi = ChatOllama(model='phi4', temperature=0, max_tokens=1000,seed=1234) \n",
    "\n",
    "\n",
    "\n",
    "## full chains\n",
    "\n",
    "chain_phi = prompt | llm_phi| parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adjusted functions for ranking\n",
    "\n",
    "def ADD(df):\n",
    "    counts = df.groupby(['groupId', 'item'])['rating'].sum().reset_index(name='sum_rating')\n",
    "    return list(counts.sort_values(by='sum_rating', ascending=False)['item'].head(10))\n",
    "    \n",
    "\n",
    "def APP(df, threshold=6):\n",
    "    above_threshold = df[df['rating'] > threshold]\n",
    "    counts = above_threshold.groupby(['groupId', 'item']).size().reset_index(name='count_above_threshold')\n",
    "    \n",
    "    all_items = df['item'].unique()\n",
    "    all_groups = df['groupId'].unique()\n",
    "    full_index = pd.MultiIndex.from_product([all_groups, all_items], names=['groupId', 'item'])\n",
    "    \n",
    "    counts = counts.set_index(['groupId', 'item']).reindex(full_index, fill_value=0).reset_index()\n",
    "    \n",
    "    return list(counts.sort_values(by='count_above_threshold', ascending=False)['item'].head(10))\n",
    "\n",
    "def LMS(df):\n",
    "    counts = df.groupby(['groupId', 'item'])['rating'].min().reset_index(name='min_rating')\n",
    "    return list(counts.sort_values(by='min_rating', ascending=False)['item'].head(10))\n",
    "\n",
    "def MPL(df):\n",
    "    counts = df.groupby(['groupId', 'item'])['rating'].max().reset_index(name='max_rating')\n",
    "    \n",
    "    return list(counts.sort_values(by='max_rating', ascending=False)['item'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123456) \n",
    "np.random.seed(123456)\n",
    "\n",
    "\n",
    "result_file = f'results/all_results-asrecords.csv'\n",
    "result_exists = os.path.isfile(result_file)\n",
    "\n",
    "###############################\n",
    "\n",
    "if result_exists == True:\n",
    "    done = pd.read_csv(result_file)\n",
    "    counter = done['groupId'].max() +1\n",
    "    max_counter = df['groupId'].max()\n",
    "\n",
    "else:\n",
    "    counter = df['groupId'].min()\n",
    "    max_counter = df['groupId'].max()\n",
    "    #max_counter = df['groupId'].min() + 3\n",
    "###############################\n",
    "\n",
    "print(counter)\n",
    "\n",
    "strategy_map = {\n",
    "    'ADD': ADD,\n",
    "    'APP': APP,\n",
    "    'LMS': LMS,\n",
    "    'MPL': MPL\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "while counter <= max_counter:\n",
    "    df_members = df.loc[df['groupId'] == counter]\n",
    "\n",
    "    random_index = random.choice([0,1,2,3])\n",
    "    chosen_strat = strat_list[random_index]\n",
    "    strat_func = [ADD, APP, LMS, MPL]\n",
    "    strat_str = ['ADD', 'APP', 'LMS', 'MPL']\n",
    "    selected_func = strat_func[random_index]\n",
    "    try:\n",
    "        \n",
    "        responses = {\n",
    "            \"phi\": chain_phi.invoke({\"desc\": df_members.iloc[:, :-1].to_dict(orient='records'),'strat':chosen_strat}),\n",
    "        }\n",
    "\n",
    "        if responses['phi']['strategy'] in strategy_map:\n",
    "            final_strat = responses['phi']['strategy']\n",
    "            gold_label = strategy_map.get(responses['phi']['strategy'])(transform_df(df_members))\n",
    "        #else:\n",
    "            #final_strat = responses['phi']['strategy']\n",
    "            #gold_label = strategy_map.get(responses['phi']['strategy'])(transform_df(df_members)) ### sometimes a formatting error can occur.\n",
    "        else:\n",
    "            counter+=1\n",
    "            print('fail', counter)\n",
    "            continue\n",
    "\n",
    "        recs = {key: listmaker(res[\"recommendation\"]) for key, res in responses.items()}\n",
    "\n",
    "        df_temp = pd.DataFrame([{\n",
    "                \"groupId\": counter,\n",
    "                \"group_size\":len(df_members),\n",
    "                \"num_items\": int(len(list(df_members))-2), ## num columns - user_id column - groupid column\n",
    "                \"strategy\": final_strat,\n",
    "                \"gold_label\": gold_label,\n",
    "                **{f\"{key}\": vec for key, vec in recs.items()} \n",
    "            }])\n",
    "\n",
    "        df_temp.to_csv(result_file, mode='a', index=False, header=not result_exists)\n",
    "        result_exists = True\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing group {counter}: {e}\")\n",
    "    counter +=1\n",
    "\n",
    "\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RANKING #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FULL INITIALIZATION OF ALL LLM CHAINS\n",
    "## A llm chain consists of three parts 1) prompt 2) model 3) parser\n",
    "\n",
    "\n",
    "#### 1) Prompt + parser\n",
    "class Recommendation(BaseModel):\n",
    "    recommendation: list = Field(description=\"python list of the final group recommendation\")\n",
    "    strategy: str = Field(description=\"The aggregation strategy that was used\")\n",
    "\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Recommendation)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Only respond with the required json format. Only respond with the recommendation and strategy keys.\n",
    "    \\n\n",
    "    {format_instructions}\\n \n",
    "\n",
    "    #######\n",
    "    \n",
    "    You are an expert in making group recommendations based on a table of ratings presented below. \n",
    "    That information includes users (user_ids) and information on which items they like (item_x). The rating is a scale from 0 to 10. \n",
    "    You recommend 10 items to the group. \n",
    "\n",
    "    The table is found below:\n",
    "    \n",
    "    ## begin group table ##\n",
    "    {desc}\n",
    "    ## end group table ##\n",
    "    \n",
    "    To obtain a group recommendation, you follow a social choice-based aggregation strategy. The strategy is explained (alongside a simple example) in the following excerpt:\n",
    "    \n",
    "    ## begin strategy excerpt ##\n",
    "    {strat}\n",
    "    ## end strategy excerpt ##\n",
    "   \n",
    "    Based on the described group composition, you strictly apply the procedure of the aggregation strategy. Do not write python code.\n",
    "    \n",
    "    You make a recommendation to this group of users by providing the top 10 items. You reply with the top 10. \n",
    "    Your recommendation contains exactly 10 items and is formatted as a python list containing strings. Refer to items using their name (item_value)\n",
    "    \n",
    "    Provide your answer strictly as a JSON object with the following format:\n",
    "{{\n",
    "  \"recommendation\": {{[\"item\",\"item\",\"item\",\"item\",\"item\",\"item\",\"item\",\"item\",\"item\",\"item\"]}},\n",
    "  \"strategy\": \"{{the strategy that was used}}\"\n",
    "}}\n",
    "\n",
    "    \"\"\" ,\n",
    "    input_variables=[\"desc\", \"strat\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "llm_phi = ChatOllama(model='phi4', temperature=0, max_tokens=1000,seed=1234) \n",
    "chain_phi = prompt | llm_phi| parser\n",
    "chain_mistral = prompt | llm_mistral | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123456) \n",
    "np.random.seed(123456)\n",
    "\n",
    "\n",
    "result_file = f'results/all_results-ranking.csv'\n",
    "result_exists = os.path.isfile(result_file)\n",
    "\n",
    "###############################\n",
    "\n",
    "if result_exists == True:\n",
    "    done = pd.read_csv(result_file)\n",
    "    counter = done['groupId'].max() +1\n",
    "    max_counter = df['groupId'].max()\n",
    "\n",
    "else:\n",
    "    counter = df['groupId'].min()\n",
    "    max_counter = df['groupId'].max()\n",
    "    #max_counter = df['groupId'].min() + 3\n",
    "###############################\n",
    "\n",
    "print(counter)\n",
    "\n",
    "strategy_map = {\n",
    "    'ADD': ADD,\n",
    "    'APP': APP,\n",
    "    'LMS': LMS,\n",
    "    'MPL': MPL\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "while counter <= max_counter:\n",
    "    df_members = df.loc[df['groupId'] == counter]\n",
    "\n",
    "    random_index = random.choice([0,1,2,3])\n",
    "    chosen_strat = strat_list[random_index]\n",
    "    strat_func = [ADD, APP, LMS, MPL]\n",
    "    strat_str = ['ADD', 'APP', 'LMS', 'MPL']\n",
    "    selected_func = strat_func[random_index]\n",
    "    try:\n",
    "        \n",
    "        responses = {\n",
    "            \"mistral\": chain_mistral.invoke({\"desc\": df_members.iloc[:, :-1].to_dict(orient='list'),'strat':chosen_strat}),\n",
    "            \"phi\": chain_phi.invoke({\"desc\": df_members.iloc[:, :-1].to_dict(orient='list'),'strat':chosen_strat}),\n",
    "        }\n",
    "\n",
    "        final_strat = strat_str[random_index]\n",
    "        gold_label = selected_func(transform_df(df_members))\n",
    "\n",
    "        recs = {key: listmaker(res[\"recommendation\"]) for key, res in responses.items()}\n",
    "\n",
    "        df_temp = pd.DataFrame([{\n",
    "                \"groupId\": counter,\n",
    "                \"group_size\":len(df_members),\n",
    "                \"num_items\": int(len(list(df_members))-2), ## num columns - user_id column - groupid column\n",
    "                \"strategy\": final_strat,\n",
    "                \"gold_label\": gold_label,\n",
    "                **{f\"{key}\": vec for key, vec in recs.items()} \n",
    "            }])\n",
    "\n",
    "        df_temp.to_csv(result_file, mode='a', index=False, header=not result_exists)\n",
    "        result_exists = True\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing group {counter}: {e}\")\n",
    "    counter +=1\n",
    "\n",
    "\n",
    "    #break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
